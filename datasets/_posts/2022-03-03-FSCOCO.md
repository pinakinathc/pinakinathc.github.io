---
layout: post
comments: true
mathjax: true
author: pinaki
permalink: /fscoco/
---

FSCOCO comprises 10,000 freehand scene vector sketches with per point
space-time information by 100 non-expert individuals, offering both object- and scene-level abstraction.

## **FSCOCO Dataset**

---

### **Abstract**
We advance sketch research to scenes with the first dataset of freehand scene sketches, FS-COCO. With practical applications in mind, we collect sketches that convey well scene content but can be sketched within a few minutes by a person with any sketching skills. Our dataset comprises 10,000 freehand scene vector sketches with per point space-time information by 100 non-expert individuals, offering both object- and scene-level abstraction. Each sketch is augmented with its text description. Using our dataset, we study for the first time the problem of fine-grained image retrieval from freehand scene sketches and sketch captions. We draw insights on: (i) Scene salience encoded in sketches using the strokes temporal order; (ii) Performance comparison of image retrieval from a scene sketch and an image caption; (iii) Complementarity of information in sketches and image captions, as well as the potential benefit of combining the two modalities. In addition, we extend a popular vector sketch LSTM-based encoder to handle sketches with larger complexity than was supported by previous work. Namely, we propose a hierarchical sketch decoder, which we leverage at a sketch-specific “pre-text” task. Our dataset enables for the first time research on freehand scene sketch understanding and its practical applications

### **Dataset Statistics**

For our dataset, we compute two estimates of the category distribution across our data: (1) Upper Bound: based on semantic segmentation labels in images and (2) Lower Bound: based on the occurrence of a word in a sketch caption. 

<table>
    <tr>
        <th>Total Sketches</th>
        <th># Categories</th>
        <th colspan="4"># Categories per Sketch</th>
        <th colspan="4"># Sketches per Category</th>
    </tr>
    <tr>
        <td colspan="2"></td>
        <td>Mean</td>
        <td>Std</td>
        <td>Min</td>
        <td>Max</td>
        <td>Mean</td>
        <td>Std</td>
        <td>Min</td>
        <td>Max</td>
    </tr>
    <tr>
        <td>10,000</td>
        <td>92/150</td>
        <td>1.37/7.17</td>
        <td>0.57/3.27</td>
        <td>1/1</td>
        <td>5/25</td>
        <td>99.42/413.18</td>
        <td>172.88/973.59</td>
        <td>1/1</td>
        <td>866/6789</td>
    </tr>
</table>
<style>
table, th, td {
  border: 1px solid black;
  text-align: center;
  padding: 15px;
}
tr:nth-child(odd) {
  background-color: #f2f2f2;
}
</style>

### **Dataset Sample and Comparison with existing dataset.**
![Sample Comparison FSCOCO dataset](/datasets/images/fscoco-sample-comparison.jpg)

## **Code**

### >> Code for Data collection tool
[**https://github.com/pinakinathc/SketchX-SST**](https://github.com/pinakinathc/SketchX-SST)

You will need to install `npm`, `nodejs`, `mongodb`, `pymongo`, `numpy`

Once you have done the setup, you are ready to run the code. I used a Linode server to host this service. It takes £5 for a month.

```
npm install
python init_db.py
sudo node server.js
```

Once you are done collecting data, you can visualise your results at scale using `python visualise_sketch.py`. You will need to install `bresenham` and `cv2` for this. Also modify Line `60, 61` to set the path of **MSCOCO** data directory and **SketchyCOCO** data directory.

### >> Code for running experiments

[**https://github.com/pinakinathc/scene-sketch-dataset**](https://github.com/pinakinathc/scene-sketch-dataset)

I use `PyTorch` and `PyTorch Lightning` for the experiments. If you face some issues with dependencies, please contant me.

I also added some code to run the experiments using HPC (i.e., Condor).

Example for running:
```
git clone https://github.com/pinakinathc/scene-sketch-dataset.git
cd scene-sketch-dataset/src/sbir_baseline
python main.py
```

Before you run `main.py` ensure that the code is set up in training mode and data path are correct in `options.py`.

### **License / Terms of Use**
The dataset is under review. Please send an email to mail@pinakinathc.me to get the password to unzip the dataset. You are not allowed to share this dataset. All rights are reserved. We shall release this dataset under Creative Commons Attribution 4.0 License once this dataset is published.

### **How to cite this dataset**
```
@article{fscoco,
    title={FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in Context.}
    author={Chowdhury, Pinaki Nath and Sain, Aneeshan and Bhunia, Ayan Kumar and Xiang, Tao and Gryaditskaya, Yulia and Song, Yi-Zhe},
    journal={arXiv preprint arXiv:2203.02113},
    year={2022}
}
```

### **Download this dataset**

Please send an email to mail@pinakinathc.me for the unZip password.

[**Download from Google Drive**](https://drive.google.com/file/d/1f4dEYbWL05Jwlr8KKdXXJioKZWcvaTJG/view?usp=sharing)

### **Acknowledgements**
This dataset would not be possible without the support of the following wonderful people:

[Anran Qi](http://sketchx.ai/), [Yue Zhong](http://sketchx.ai/), [Lan Yang](http://sketchx.ai/), [Dongliang Chang](https://scholar.google.com/citations?user=tIf50PgAAAAJ&hl=en), [Ling Luo](https://rowl1ng.com/), [Ayan Das](https://scholar.google.com/citations?user=x-WI_EgAAAAJ&hl=en), [Zhiyu Qu](http://sketchx.ai/), [Yixiao Zheng](http://sketchx.ai/), [Ruolin Yang](http://sketchx.ai/), [Ranit](https://github.com/MaestroRon-001)
